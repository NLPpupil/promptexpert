{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f32883-fc9e-419e-8096-bd5c5d2d00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/salesforce/LAVIS/blob/main/lavis/models/blip2_models/blip2_qformer.py#L101\n",
    "# Blip2Qformer的forward方法\n",
    "query_output = self.Qformer.bert(\n",
    "    query_embeds=query_tokens,\n",
    "    encoder_hidden_states=image_embeds,\n",
    "    encoder_attention_mask=image_atts,\n",
    "    use_cache=True,\n",
    "    return_dict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc340944-1475-405a-a328-502a44bc3b6a",
   "metadata": {},
   "source": [
    "这里计算的是queries的self attention，图片的self attention，以及两者的cross attention。\n",
    "\n",
    "self.Qformer.bert是BertModel类。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84d4d475-b321-4087-ab9a-5653b9ad253c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b46310-4f10-41cb-ab28-9fa757a68be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/salesforce/LAVIS/blob/main/lavis/models/blip2_models/Qformer.py#L804\n",
    "# BertModel类的forward方法\n",
    "def forward(\n",
    "    self,\n",
    "    input_ids=None,\n",
    "    attention_mask=None,\n",
    "    position_ids=None,\n",
    "    head_mask=None,\n",
    "    query_embeds=None,\n",
    "    encoder_hidden_states=None,\n",
    "    encoder_attention_mask=None,\n",
    "    past_key_values=None,\n",
    "    use_cache=None,\n",
    "    output_attentions=None,\n",
    "    output_hidden_states=None,\n",
    "    return_dict=None,\n",
    "    is_decoder=False,\n",
    "):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa8658-a665-4ff1-a1bc-18d74ecfca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "在ITC任务的图片特征计算中，`BertModel.forward()`的张量参数有且只有：\n",
    "\n",
    "- query_embeds，queries向量\n",
    "- encoder_hidden_states，图片向量\n",
    "- encoder_attention_mask，图片attention mask\n",
    "\n",
    "这里有个细节，图片向量不计算self attention，直接作为encoder_hidden_states，和queries计算cross attention。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b49fd4d5-a84e-4ff2-abf9-11f9cc1856c6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8020f71-5a0a-43df-a27a-9440a3e6110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertModel类的forward方法\n",
    "past_key_values_length = (\n",
    "    past_key_values[0][0].shape[2] - self.config.query_length\n",
    "    if past_key_values is not None\n",
    "    else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e386d74-129e-45c7-a953-2bc3405d9136",
   "metadata": {},
   "source": [
    "past_key_values_length=0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e02046ff-ae0d-4b9b-8ef6-0ef443cbf979",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4d279c-9637-4335-a5cc-7385c02a8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_length = query_embeds.shape[1] if query_embeds is not None else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166aea7-4be9-4035-b2fb-0d720a0fe32f",
   "metadata": {},
   "source": [
    "query_length = 32"
   ]
  },
  {
   "cell_type": "raw",
   "id": "477aca68-4b63-4448-b521-dc9d3efef492",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d7bdbb-365c-4cf5-9bf2-41733809f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertModel类的forward方法\n",
    "embedding_output = self.embeddings(\n",
    "    input_ids=input_ids,\n",
    "    position_ids=position_ids,\n",
    "    query_embeds=query_embeds,\n",
    "    past_key_values_length=past_key_values_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d577c98-4449-490b-a496-3be24ba634d2",
   "metadata": {},
   "source": [
    "这块代码只有当提供input_ids时才实际运行，否则embedding_output就是query_embeds。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9181b917-de46-4cf8-96d0-49085a50f86a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca940ec-f32e-438a-b0de-b257fe303d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = embedding_output.size()[:-1]\n",
    "batch_size, seq_length = input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d88ffb-f29b-4757-9616-16785234c3b6",
   "metadata": {},
   "source": [
    "seq_length = query_length"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fd7a54d-2ef2-4d44-a8f1-cc8d6195d2a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d11239-7cef-40d7-9c89-74536a9ebd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "if attention_mask is None:\n",
    "    attention_mask = torch.ones(\n",
    "        ((batch_size, seq_length + past_key_values_length)), device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21282608-d6f6-4ab6-a3de-38beb257e875",
   "metadata": {},
   "source": [
    "attention_mask是queries的mask。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d40631cf-5507-44e0-9474-c5dd9ce22567",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bbd369-1536-40f9-8871-55b8f1b1811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_decoder:\n",
    "   # ...\n",
    "else:\n",
    "    extended_attention_mask = self.get_extended_attention_mask(\n",
    "        attention_mask, input_shape, device, is_decoder\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e9d27-5b8b-4497-8dc8-0a5ff3fa73e5",
   "metadata": {},
   "source": [
    "is_decoder=False"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23ff568d-799c-4c93-9df2-3f638ffe4f8c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf59da-0897-4e2b-88df-dae71e929d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertModel类的get_extended_attention_mask方法\n",
    "if attention_mask.dim() == 3: \n",
    "    # ...\n",
    "elif attention_mask.dim() == 2:\n",
    "    if is_decoder:\n",
    "        # ...\n",
    "    else:\n",
    "        extended_attention_mask = attention_mask[:, None, None, :]\n",
    "extended_attention_mask = extended_attention_mask.to(\n",
    "    dtype=self.dtype\n",
    ")  # fp16 compatibility\n",
    "extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "return extended_attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba22901-0947-4ef0-92ce-e28adbb2996c",
   "metadata": {},
   "source": [
    "attention_mask[:, None, None, :]将attention_mask扩展为[batch_size, num_heads=1, seq_length=1, seq_length]。\n",
    "num_heads和seq_length=1在应用的时候，会被广播到相应的size。\n",
    "第一个 seq_length：表示查询序列的长度，即我们正在处理的输入序列的每个位置。第二个 seq_length：表示key序列的长度，通常等于查询序列的长度。\n",
    "\n",
    "attention_mask的1是有效位置，0是无效位置。(1.0 - extended_attention_mask) * -10000.0操作后，有效位置变成0，无效位置-10000. 这样在softmax之后，无效位置接近于0."
   ]
  },
  {
   "cell_type": "raw",
   "id": "77380e46-3c0b-4991-a9ed-270092f31615",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afef992a-5ee6-4641-b925-a07be3340fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertModel类的forward方法\n",
    "if encoder_hidden_states is not None:\n",
    "    # ...\n",
    "else:\n",
    "    encoder_extended_attention_mask = None\n",
    "# Prepare head mask if needed\n",
    "# 1.0 in head_mask indicate we keep the head\n",
    "# attention_probs has shape bsz x n_heads x N x N\n",
    "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\n",
    "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\n",
    "head_mask = self.get_head_mask(head_mask, self.config.num_hidden_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d697b8d-9a5e-4073-9a54-fc143bb2fb62",
   "metadata": {},
   "source": [
    "输入head_mask=None，那么所有head都不被屏蔽。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5224147-d67f-4168-b3a5-593e6333a2a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf12bb1-6676-4217-bac5-42f86009cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertModel类的forward方法\n",
    "encoder_outputs = self.encoder(\n",
    "    embedding_output,\n",
    "    attention_mask=extended_attention_mask,\n",
    "    head_mask=head_mask,\n",
    "    encoder_hidden_states=encoder_hidden_states,\n",
    "    encoder_attention_mask=encoder_extended_attention_mask,\n",
    "    past_key_values=past_key_values,\n",
    "    use_cache=use_cache,\n",
    "    output_attentions=output_attentions,\n",
    "    output_hidden_states=output_hidden_states,\n",
    "    return_dict=return_dict,\n",
    "    query_length=query_length,\n",
    ")\n",
    "\n",
    "# BertEncoder的forward方法\n",
    "def forward(\n",
    "    self,\n",
    "    hidden_states,\n",
    "    attention_mask=None,\n",
    "    head_mask=None,\n",
    "    encoder_hidden_states=None,\n",
    "    encoder_attention_mask=None,\n",
    "    past_key_values=None,\n",
    "    use_cache=None,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    return_dict=True,\n",
    "    query_length=0,\n",
    "):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ea9870-29a6-4029-986c-58534ea8f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states=query_embeds\n",
    "attention_mask=extended_attention_mask\n",
    "head_mask=head_mask\n",
    "encoder_hidden_states=image_embeds\n",
    "encoder_attention_mask=image_atts\n",
    "use_cache=True\n",
    "output_attentions=None\n",
    "output_hidden_states=None\n",
    "return_dict=True\n",
    "query_length=query_length"
   ]
  },
  {
   "cell_type": "raw",
   "id": "502ee703-4cee-451a-8765-aa2d3ec1d9e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf6642-7b79-49b6-b3dc-fd2b1a5c05b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertEncoder的forward方法\n",
    "all_hidden_states = () if output_hidden_states else None # None\n",
    "all_self_attentions = () if output_attentions else None # None\n",
    "all_cross_attentions = (\n",
    "    () if output_attentions and self.config.add_cross_attention else None\n",
    ") # None\n",
    "\n",
    "next_decoder_cache = () if use_cache else None # ()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0a6f9db-0e91-410c-88f7-1c8175c01356",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d3c7b-0376-435d-ab33-dc172052529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertEncoder的forward方法\n",
    "for i in range(self.config.num_hidden_layers):\n",
    "    layer_module = self.layer[i]\n",
    "    if output_hidden_states:\n",
    "        # ...\n",
    "\n",
    "    layer_head_mask = head_mask[i] if head_mask is not None else None\n",
    "    past_key_value = past_key_values[i] if past_key_values is not None else None # None\n",
    "\n",
    "    if getattr(self.config, \"gradient_checkpointing\", False) and self.training:\n",
    "        # 略\n",
    "    else:\n",
    "        layer_outputs = layer_module(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            layer_head_mask,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask,\n",
    "            past_key_value,\n",
    "            output_attentions,\n",
    "            query_length,\n",
    "        )\n",
    "    hidden_states = layer_outputs[0]\n",
    "    if use_cache:\n",
    "        next_decoder_cache += (layer_outputs[-1],)\n",
    "    if output_attentions:\n",
    "        # ...\n",
    "        \n",
    "if output_hidden_states:\n",
    "    # ...\n",
    "\n",
    "if not return_dict:\n",
    "    # ...\n",
    "return BaseModelOutputWithPastAndCrossAttentions(\n",
    "    last_hidden_state=hidden_states,\n",
    "    past_key_values=next_decoder_cache,\n",
    "    hidden_states=all_hidden_states,\n",
    "    attentions=all_self_attentions,\n",
    "    cross_attentions=all_cross_attentions,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8f25999-d370-44fc-8327-1b0da3a4c3d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b972a2-6cd1-491c-bfee-0727f7135137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertLayer的forward方法\n",
    "def forward(\n",
    "    self,\n",
    "    hidden_states,\n",
    "    attention_mask=None,\n",
    "    head_mask=None,\n",
    "    encoder_hidden_states=None,\n",
    "    encoder_attention_mask=None,\n",
    "    past_key_value=None,\n",
    "    output_attentions=False,\n",
    "    query_length=0,\n",
    "):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b402c86-ffee-4c5c-99d6-0bfb3f65e465",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states=query_embeds\n",
    "attention_mask=extended_attention_mask\n",
    "head_mask=head_mask\n",
    "encoder_hidden_states=image_embeds\n",
    "encoder_attention_mask=image_atts\n",
    "past_key_value=None\n",
    "output_attentions=None\n",
    "output_hidden_states=None\n",
    "query_length=query_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9999d972-506c-423d-8d03-6351d9e5f928",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf36393-c031-4a3b-9ebb-ffe867790b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertLayer的forward方法\n",
    "# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
    "self_attn_past_key_value = (\n",
    "    past_key_value[:2] if past_key_value is not None else None\n",
    ") # None\n",
    "self_attention_outputs = self.attention(\n",
    "    hidden_states,\n",
    "    attention_mask,\n",
    "    head_mask,\n",
    "    output_attentions=output_attentions,\n",
    "    past_key_value=self_attn_past_key_value,\n",
    ")\n",
    "attention_output = self_attention_outputs[0]\n",
    "outputs = self_attention_outputs[1:-1]\n",
    "\n",
    "present_key_value = self_attention_outputs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40af99e1-d302-4c4f-a8ad-a1d38bcbce38",
   "metadata": {},
   "source": [
    "计算queries的self attention。\n",
    "self_attention_outputs是三元组，元素分别是：\n",
    "- 元素0：attention_output这个是自注意力层的主要输出，是经过注意力机制计算后的隐状态。它的形状通常为 (batch_size, sequence_length, hidden_size)。\n",
    "- 元素1：attention_weights（如果 output_attentions=True）：这个是注意力权重（attention weights），表示计算注意力得分时的权重矩阵。它的形状通常为 (batch_size, num_heads, sequence_length, sequence_length)。\n",
    "- 元素2：present_key_value：这个是用来保存注意力计算中键和值、的缓存，用于加速后续的推理或者训练。它的形状通常是 ((batch_size, num_heads, sequence_length, head_dim), (batch_size, num_heads, sequence_length, head_dim))，分别对应键和值。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3b6f057-a359-4e85-bcb6-b55788ea7474",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6115a5e6-fb71-463a-9b25-0fef491c167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertLayer的forward方法\n",
    "if query_length > 0:\n",
    "    query_attention_output = attention_output[:, :query_length, :]\n",
    "\n",
    "    if self.has_cross_attention: # True\n",
    "        assert (\n",
    "            encoder_hidden_states is not None\n",
    "        ), \"encoder_hidden_states must be given for cross-attention layers\"\n",
    "        cross_attention_outputs = self.crossattention(\n",
    "            query_attention_output,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        query_attention_output = cross_attention_outputs[0]\n",
    "        outputs = (\n",
    "            outputs + cross_attention_outputs[1:-1]\n",
    "        )  # add cross attentions if we output attention weights\n",
    "\n",
    "    layer_output = apply_chunking_to_forward(\n",
    "        self.feed_forward_chunk_query,\n",
    "        self.chunk_size_feed_forward,\n",
    "        self.seq_len_dim,\n",
    "        query_attention_output,\n",
    "    )\n",
    "    \n",
    "    if attention_output.shape[1] > query_length: # False\n",
    "        # ...\n",
    "outputs = (layer_output,) + outputs\n",
    "\n",
    "outputs = outputs + (present_key_value,)\n",
    "\n",
    "return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba008422-c7ee-4c83-9f1e-2cbb23527db6",
   "metadata": {},
   "source": [
    "query_attention_output = attention_output[:, :query_length, :]在这里是多余的，因为attention_output本来就是queries的self attention。\n",
    "\n",
    "self.crossattention计算queries和image_embeds的cross attention。\n",
    "\n",
    "apply_chunking_to_forward是transformers自带的函数。处理长序列输入时，内存占用可能非常高。通过分块处理，可以将输入序列分成若干个小块，每次只处理一个小块，从而减少单次计算所需的内存量。chunk_size_feed_forward定义在 https://huggingface.co/docs/transformers/main_classes/configuration , 如果bert-base-uncased没有配置，则默认为0. The chunk size of all feed forward layers in the residual attention blocks. A chunk size of 0 means that the feed forward layer is not chunked. A chunk size of n means that the feed forward layer processes n < sequence_length embeddings at a time. \n",
    "\n",
    "outputs是3元组，元素分别是：\n",
    "- 注意力机制计算后的隐藏状态\n",
    "- attention_weights\n",
    "- present_key_value"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a670d538-7222-429e-8ccd-a2288ef2cba4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c2dd49-a43e-4c6b-a81c-9607021d8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertEncoder的forward方法\n",
    "for i in range(self.config.num_hidden_layers):\n",
    "    # ...\n",
    "    else:\n",
    "        layer_outputs = layer_module(\n",
    "            hidden_states\n",
    "            # ...\n",
    "        )\n",
    "    hidden_states = layer_outputs[0]\n",
    "    if use_cache:\n",
    "        next_decoder_cache += (layer_outputs[-1],)\n",
    "    if output_attentions:\n",
    "        # ...\n",
    "        \n",
    "return BaseModelOutputWithPastAndCrossAttentions(\n",
    "    last_hidden_state=hidden_states,\n",
    "    past_key_values=next_decoder_cache,\n",
    "    hidden_states=all_hidden_states,\n",
    "    attentions=all_self_attentions,\n",
    "    cross_attentions=all_cross_attentions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75deda22-aba3-4926-957e-782e8c893457",
   "metadata": {},
   "source": [
    "逐层计算self attention和cross attention，返回最后一层的隐状态。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6259a791-0c2c-45b4-aabe-709fd05d8fb5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7134afc8-aad6-4f91-9c79-4b916ffab00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertModel类的forward方法\n",
    "encoder_outputs = self.encoder(\n",
    "    # ...\n",
    "    )\n",
    "sequence_output = encoder_outputs[0]\n",
    "pooled_output = (\n",
    "    self.pooler(sequence_output) if self.pooler is not None else None\n",
    ") # None\n",
    "\n",
    "if not return_dict:\n",
    "    # ...\n",
    "\n",
    "return BaseModelOutputWithPoolingAndCrossAttentions(\n",
    "    last_hidden_state=sequence_output,\n",
    "    pooler_output=pooled_output,\n",
    "    past_key_values=encoder_outputs.past_key_values,\n",
    "    hidden_states=encoder_outputs.hidden_states,\n",
    "    attentions=encoder_outputs.attentions,\n",
    "    cross_attentions=encoder_outputs.cross_attentions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37829213-ecb5-4b38-ad08-9ca8d34d9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_output是逐层计算self attention和cross attention，返回最后一层的隐状态的结果。\n",
    "\n",
    "没用pooling，最终返回的还是sequence_output。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ce88f4d-c6ca-4dcb-a907-c465d4f19f38",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f9a7d-6792-4cb7-bceb-1e0dd4b912b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blip2Qformer的forward方法\n",
    "query_output = self.Qformer.bert(\n",
    "    query_embeds=query_tokens,\n",
    "    encoder_hidden_states=image_embeds,\n",
    "    encoder_attention_mask=image_atts,\n",
    "    use_cache=True,\n",
    "    return_dict=True,\n",
    ")\n",
    "\n",
    "# ...\n",
    "\n",
    "text_output = self.Qformer.bert(\n",
    "    text_tokens.input_ids,\n",
    "    attention_mask=text_tokens.attention_mask,\n",
    "    return_dict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba35023b-cb83-45a9-b3dd-6c10664659aa",
   "metadata": {},
   "source": [
    "计算完图片特征后，再计算文本特征。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2c68331-27da-4bea-b2b2-aa822f583f29",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b5526-3c95-4a09-8f9f-87c4d6d9e392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/salesforce/LAVIS/blob/main/lavis/models/blip2_models/Qformer.py#L804\n",
    "# BertModel类的forward方法\n",
    "def forward(\n",
    "    self,\n",
    "    input_ids=None,\n",
    "    attention_mask=None,\n",
    "    position_ids=None,\n",
    "    head_mask=None,\n",
    "    query_embeds=None,\n",
    "    encoder_hidden_states=None,\n",
    "    encoder_attention_mask=None,\n",
    "    past_key_values=None,\n",
    "    use_cache=None,\n",
    "    output_attentions=None,\n",
    "    output_hidden_states=None,\n",
    "    return_dict=None,\n",
    "    is_decoder=False,\n",
    "):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82194a51-6095-4c87-a72c-02fb0b53dfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "在ITC任务的文本特征计算中\n",
    "- input_ids=text_tokens.input_ids\n",
    "- attention_mask=text_tokens.attention_mask\n",
    "- return_dict=True\n",
    "- 其他默认"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bc32829-bbc4-4427-8154-b9bfb905c094",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe7364-8a28-44aa-8a94-dd7d51ee3821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertModel类的forward方法\n",
    "# ...\n",
    "query_length = query_embeds.shape[1] if query_embeds is not None else 0 #0\n",
    "embedding_output = self.embeddings(\n",
    "    input_ids=input_ids,\n",
    "    position_ids=position_ids,\n",
    "    query_embeds=query_embeds,\n",
    "    past_key_values_length=past_key_values_length,\n",
    ")\n",
    "\n",
    "# ...\n",
    "if is_decoder:\n",
    "    # ...\n",
    "else:\n",
    "    extended_attention_mask = self.get_extended_attention_mask(\n",
    "        attention_mask, input_shape, device, is_decoder\n",
    "    )\n",
    "\n",
    "# ...\n",
    "\n",
    "encoder_outputs = self.encoder(\n",
    "    embedding_output,\n",
    "    attention_mask=extended_attention_mask,\n",
    "    head_mask=head_mask,\n",
    "    encoder_hidden_states=encoder_hidden_states,\n",
    "    encoder_attention_mask=encoder_extended_attention_mask,\n",
    "    past_key_values=past_key_values,\n",
    "    use_cache=use_cache,\n",
    "    output_attentions=output_attentions,\n",
    "    output_hidden_states=output_hidden_states,\n",
    "    return_dict=return_dict,\n",
    "    query_length=query_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e03cc2d-af90-4bdf-9e96-195872749219",
   "metadata": {},
   "source": [
    "query_length=0\n",
    "extended_attention_mask的计算方式和图片特征中的计算同理。\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fcded769-3b4b-45b7-aaea-e44e8c3c239b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa686fa-d3c5-4110-8122-c1813d8c392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertEncoder类的forward方法\n",
    "def forward(\n",
    "    self,\n",
    "    hidden_states,\n",
    "    attention_mask=None,\n",
    "    head_mask=None,\n",
    "    encoder_hidden_states=None,\n",
    "    encoder_attention_mask=None,\n",
    "    past_key_values=None,\n",
    "    use_cache=None,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    return_dict=True,\n",
    "    query_length=0,\n",
    "):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad20027-ffd9-4420-aa02-51f30c186e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states=embedding_output\n",
    "attention_mask=extended_attention_mask\n",
    "head_mask=head_mask\n",
    "encoder_hidden_states=None\n",
    "encoder_attention_mask=None\n",
    "use_cache=True\n",
    "output_attentions=None\n",
    "output_hidden_states=None\n",
    "return_dict=True\n",
    "query_length=0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b06e9b0f-f77b-4cfc-b19d-8fece89971e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced14206-7105-46b9-8f3e-9227291e98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertEncoder类的forward方法\n",
    "# ...\n",
    "for i in range(self.config.num_hidden_layers):\n",
    "    layer_module = self.layer[i]\n",
    "    # ...\n",
    "    if getattr(self.config, \"gradient_checkpointing\", False) and self.training:\n",
    "        # ...\n",
    "    else:\n",
    "        layer_outputs = layer_module(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            layer_head_mask,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask,\n",
    "            past_key_value,\n",
    "            output_attentions,\n",
    "            query_length,\n",
    "        )\n",
    "#..."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b672d0b-0565-4684-80da-dc16d2f6da88",
   "metadata": {},
   "source": [
    "这里只逐层计算文本的self attention，没有cross attention。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d16a880a-a930-4fd0-89f9-2699ea910369",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60cd80a9-2e34-4694-991c-ad6cdabf6a39",
   "metadata": {},
   "source": [
    "到这里，queries的self attention, 和图片向量的cross attention, 文本的self attention，就都计算完成了。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
