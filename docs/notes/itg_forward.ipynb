{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf7f49-273e-4cb1-8007-dbdea43c7b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/salesforce/LAVIS/blob/main/lavis/models/blip2_models/blip2_qformer.py#L260\n",
    "decoder_input_ids = text_tokens.input_ids.clone()\n",
    "decoder_input_ids[:, 0] = self.tokenizer.bos_token_id\n",
    "labels = decoder_input_ids.masked_fill(\n",
    "    decoder_input_ids == self.tokenizer.pad_token_id, -100\n",
    ")\n",
    "\n",
    "query_atts = torch.ones(query_tokens.size()[:-1], dtype=torch.long).to(\n",
    "    image.device\n",
    ")\n",
    "attention_mask = torch.cat([query_atts, text_tokens.attention_mask], dim=1)\n",
    "lm_output = self.Qformer(\n",
    "    decoder_input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    past_key_values=query_output.past_key_values,\n",
    "    return_dict=True,\n",
    "    labels=labels,\n",
    ")\n",
    "\n",
    "loss_lm = lm_output.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3607bf-2b59-45cd-a8ef-b506477680ff",
   "metadata": {},
   "source": [
    "注意forward的细微变化，这里是self.Qformer()，而不是self.Qformer.bert()。self.Qformer是BertLMHeadModel类。\n",
    "\n",
    "这里在进行语言建模，在解码，只需要query_output的kv，不需要它的隐状态，所以past_key_values=query_output.past_key_values。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84cbc583-bed6-490f-a60a-793e2f1cfdbe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b47ed6-cbbb-4e30-a1b8-6aaf776bcf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/salesforce/LAVIS/blob/main/lavis/models/blip2_models/Qformer.py#L987\n",
    "# BertLMHeadModel的forward方法\n",
    "def forward(\n",
    "    self,\n",
    "    input_ids=None,\n",
    "    attention_mask=None,\n",
    "    position_ids=None,\n",
    "    head_mask=None,\n",
    "    query_embeds=None,\n",
    "    encoder_hidden_states=None,\n",
    "    encoder_attention_mask=None,\n",
    "    labels=None,\n",
    "    past_key_values=None,\n",
    "    use_cache=True,\n",
    "    output_attentions=None,\n",
    "    output_hidden_states=None,\n",
    "    return_dict=None,\n",
    "    return_logits=False,\n",
    "    is_decoder=True,\n",
    "    reduction=\"mean\",\n",
    "):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76748b77-f755-4233-a04c-9afc40ca037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=decoder_input_ids\n",
    "attention_mask=attention_mask\n",
    "past_key_values=query_output.past_key_values\n",
    "labels=labels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e045c1a3-3206-42ce-896e-d394d20535ad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a2144b-122b-4cc4-b7f6-280abee79de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertLMHeadModel的forward方法\n",
    "# ...\n",
    "if past_key_values is not None:\n",
    "    query_embeds = None\n",
    "\n",
    "outputs = self.bert(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    position_ids=position_ids,\n",
    "    head_mask=head_mask,\n",
    "    query_embeds=query_embeds,\n",
    "    encoder_hidden_states=encoder_hidden_states,\n",
    "    encoder_attention_mask=encoder_attention_mask,\n",
    "    past_key_values=past_key_values,\n",
    "    use_cache=use_cache,\n",
    "    output_attentions=output_attentions,\n",
    "    output_hidden_states=output_hidden_states,\n",
    "    return_dict=return_dict,\n",
    "    is_decoder=is_decoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0899ec94-a5fa-483d-bcbb-b4a4b450e250",
   "metadata": {},
   "source": [
    "如果提供了past_key_values，说明是解码阶段，不需要query_embeds。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "311afe12-3764-49c8-b2f2-74cf3c4b1f69",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda7163-5c6d-495b-ad53-debe4086afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/salesforce/LAVIS/blob/main/lavis/models/blip2_models/Qformer.py#L804\n",
    "# BertModel类的forward方法\n",
    "def forward(\n",
    "    self,\n",
    "    input_ids=None,\n",
    "    attention_mask=None,\n",
    "    position_ids=None,\n",
    "    head_mask=None,\n",
    "    query_embeds=None,\n",
    "    encoder_hidden_states=None,\n",
    "    encoder_attention_mask=None,\n",
    "    past_key_values=None,\n",
    "    use_cache=None,\n",
    "    output_attentions=None,\n",
    "    output_hidden_states=None,\n",
    "    return_dict=None,\n",
    "    is_decoder=False,\n",
    "):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11567c2b-d0ab-4dbd-a908-65707dbe4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=decoder_input_ids\n",
    "attention_mask=attention_mask\n",
    "past_key_values=query_output.past_key_values\n",
    "is_decoder=True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "469ee416-72f0-45ad-83ad-6796f4f65c0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0f959-4646-43ef-94b0-6c258a6af5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertModel类的forward方法\n",
    "# ...\n",
    "past_key_values_length = (\n",
    "    past_key_values[0][0].shape[2] - self.config.query_length\n",
    "    if past_key_values is not None\n",
    "    else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7de789-3dd0-404a-8a93-f36714efd510",
   "metadata": {},
   "source": [
    "past_key_values[0][0] 取出了第一个注意力头的第一个键。它的形状是 (batch_size, num_heads, seq_length, head_dim)。\n",
    "past_key_values[0][0].shape[2] 取得了序列长度（seq_length）。\n",
    "\n",
    "这段代码的目的是确定在当前推理步骤中，已经处理过的序列长度。这个长度减去当前查询序列长度，就得到了 past_key_values_length。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c9ec034-2f4f-4884-b511-8f5c22be0e01",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a744da0c-71b3-45c7-9b7b-85db15ef7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertModel类的forward方法\n",
    "query_length = query_embeds.shape[1] if query_embeds is not None else 0 \n",
    "\n",
    "embedding_output = self.embeddings(\n",
    "    input_ids=input_ids,\n",
    "    position_ids=position_ids,\n",
    "    query_embeds=query_embeds,\n",
    "    past_key_values_length=past_key_values_length,\n",
    ")\n",
    "\n",
    "input_shape = embedding_output.size()[:-1]\n",
    "batch_size, seq_length = input_shape\n",
    "device = embedding_output.device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf5ba14-e94b-41c8-ac5a-51edce52526a",
   "metadata": {},
   "source": [
    "此query_length非彼self.config.query_length， query_length=0.\n",
    "\n",
    "past_key_values_length用于推导position_ids的位置范围。\n",
    "\n",
    "embedding_output是文本的embeddings。seq_length是文本的token数量。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "697e745f-2bef-4664-b64e-67d5a2e98544",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da7f2d-34a4-4594-882a-de215ba78860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertModel类的forward方法\n",
    "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "# ourselves in which case we just need to make it broadcastable to all heads.\n",
    "if is_decoder:\n",
    "    extended_attention_mask = self.get_extended_attention_mask(\n",
    "        attention_mask,\n",
    "        input_ids.shape,\n",
    "        device,\n",
    "        is_decoder,\n",
    "        has_query=(query_embeds is not None),\n",
    "    )\n",
    "else:\n",
    "    # ...\n",
    "\n",
    "# get_extended_attention_mask方法\n",
    "def get_extended_attention_mask(\n",
    "    self,\n",
    "    attention_mask=attention_mask,\n",
    "    input_shape=input_ids.shape,\n",
    "    device=device,\n",
    "    is_decoder: True,\n",
    "    has_query: False,\n",
    ") -> Tensor:\n",
    "    # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n",
    "    # ourselves in which case we just need to make it broadcastable to all heads.\n",
    "    if attention_mask.dim() == 3:\n",
    "        # ...\n",
    "    else:\n",
    "        if is_decoder:\n",
    "            batch_size, seq_length = input_shape\n",
    "\n",
    "            seq_ids = torch.arange(seq_length, device=device)\n",
    "            causal_mask = (\n",
    "                seq_ids[None, None, :].repeat(batch_size, seq_length, 1)\n",
    "                <= seq_ids[None, :, None]\n",
    "            )\n",
    "\n",
    "            # add a prefix ones mask to the causal mask\n",
    "            # causal and attention masks must have same type with pytorch version < 1.3\n",
    "            causal_mask = causal_mask.to(attention_mask.dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec43567-d747-4272-bb86-b0928220a738",
   "metadata": {},
   "outputs": [],
   "source": [
    "这是计算attention mask的地方，划重点。\n",
    "\n",
    "causal_mask就是用于语言建模的mask，即某个位置只能注意到前面已经解码过的词。\n",
    "- seq_ids[None, None, :] 通过增加两个维度变成形状为 (1, 1, seq_length) 的张量。\n",
    "- eq_ids[None, None, :].repeat(batch_size, seq_length, 1) 通过重复操作变成形状为 (batch_size, seq_length, seq_length) 的张量。\n",
    "- seq_ids[None, :, None] 通过增加两个维度变成形状为 (1, seq_length, 1) 的张量。\n",
    "- seq_ids[None, None, :].repeat(batch_size, seq_length, 1) <= seq_ids[None, :, None] 通过比较操作生成一个布尔型张量，形状为 (batch_size, seq_length, seq_length)。\n",
    "\n",
    "causal mask举例：\n",
    "[[ True, False, False],\n",
    "[ True,  True, False],\n",
    "[ True,  True,  True]]\n",
    "生成的 causal_mask 是一个三维布尔张量，形状为 (batch_size, seq_length, seq_length)。\n",
    "对于每个位置 i，只有位置 i 及其之前的位置 j (即 j <= i) 才会是 True，其他位置是 False。这确保了在注意力计算中，位置 i 只能关注到位置 i 及其之前的位置，而不能看到未来的位置。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18b07441-b1fa-4f30-babd-8a7b3c11f3c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f188d-6e73-42aa-8215-87af2abd4ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_extended_attention_mask方法\n",
    "if causal_mask.shape[1] < attention_mask.shape[1]:\n",
    "    prefix_seq_len = attention_mask.shape[1] - causal_mask.shape[1]\n",
    "    if has_query:  # UniLM style attention mask\n",
    "        # ...\n",
    "    causal_mask = torch.cat(\n",
    "        [\n",
    "            torch.ones(\n",
    "                (batch_size, causal_mask.shape[1], prefix_seq_len),\n",
    "                device=device,\n",
    "                dtype=causal_mask.dtype,\n",
    "            ),\n",
    "            causal_mask,\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "extended_attention_mask = (\n",
    "    causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b69465f-8653-467d-9ad6-301fd672a1df",
   "metadata": {},
   "source": [
    "这部分是给图像queries的mask设置为1。prefix_seq_len就是图像queries的数量。\n",
    "\n",
    "最后，将因果掩码和注意力掩码结合起来，生成一个扩展的注意力掩码 extended_attention_mask：\n",
    "causal_mask[:, None, :, :] 为 causal_mask 的第二维度添加一个新维度，形状变为 (batch_size, 1, seq_length, seq_length)。\n",
    "attention_mask[:, None, None, :] 为 attention_mask 的第二和第三维度添加新维度，形状变为 (batch_size, 1, 1, attention_mask_length)。\n",
    "两者相乘，得到最终的 extended_attention_mask，形状为 (batch_size, 1, seq_length, attention_mask_length)。\n",
    "这个扩展的注意力掩码将同时考虑因果性和实际的注意力掩码，从而确保在自注意力机制中正确地应用注意力权重。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18d0c9e5-bb72-41e9-a442-051e6fe470f4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5935a4dd-d695-4396-a4da-55a579dcdd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertModel类的forward方法\n",
    "if encoder_hidden_states is not None:\n",
    "    # ...\n",
    "else:\n",
    "    encoder_extended_attention_mask = None\n",
    "\n",
    "# ...\n",
    "\n",
    "encoder_outputs = self.encoder(\n",
    "    embedding_output,\n",
    "    attention_mask=extended_attention_mask,\n",
    "    head_mask=head_mask,\n",
    "    encoder_hidden_states=encoder_hidden_states,\n",
    "    encoder_attention_mask=encoder_extended_attention_mask,\n",
    "    past_key_values=past_key_values,\n",
    "    use_cache=use_cache,\n",
    "    output_attentions=output_attentions,\n",
    "    output_hidden_states=output_hidden_states,\n",
    "    return_dict=return_dict,\n",
    "    query_length=query_length,\n",
    ")\n",
    "\n",
    "# BertEncoder的forward方法\n",
    "def forward(\n",
    "    self,\n",
    "    hidden_states,\n",
    "    attention_mask=None,\n",
    "    head_mask=None,\n",
    "    encoder_hidden_states=None,\n",
    "    encoder_attention_mask=None,\n",
    "    past_key_values=None,\n",
    "    use_cache=None,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    return_dict=True,\n",
    "    query_length=0,\n",
    "):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee76a36-d21b-4b07-9fee-3608147a2844",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states=embedding_output\n",
    "attention_mask=extended_attention_mask\n",
    "past_key_values=query_output.past_key_values\n",
    "query_length=0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f3ec2819-039a-4166-bf22-ac8ae537c63d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0413370-1737-4bde-9fe0-0009bb21890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertEncoder的forward方法\n",
    "for i in range(self.config.num_hidden_layers):\n",
    "    layer_module = self.layer[i]\n",
    "        \n",
    "    # ...\n",
    "\n",
    "    layer_head_mask = head_mask[i] if head_mask is not None else None\n",
    "    past_key_value = past_key_values[i] if past_key_values is not None else None \n",
    "\n",
    "    if getattr(self.config, \"gradient_checkpointing\", False) and self.training:\n",
    "        # 略\n",
    "    else:\n",
    "        layer_outputs = layer_module(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            layer_head_mask,\n",
    "            encoder_hidden_states,\n",
    "            encoder_attention_mask,\n",
    "            past_key_value,\n",
    "            output_attentions,\n",
    "            query_length,\n",
    "        )\n",
    "    # ...\n",
    "\n",
    "# BertLayer的forward方法\n",
    "def forward(\n",
    "    self,\n",
    "    hidden_states,\n",
    "    attention_mask=None,\n",
    "    head_mask=None,\n",
    "    encoder_hidden_states=None,\n",
    "    encoder_attention_mask=None,\n",
    "    past_key_value=None,\n",
    "    output_attentions=False,\n",
    "    query_length=0,\n",
    "):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c60a6c-74fd-4094-bdab-4552c320b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states=embedding_output\n",
    "attention_mask=extended_attention_mask\n",
    "past_key_values=query_output.past_key_values\n",
    "query_length=0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8dc2ac8-b687-4893-b919-6c64ec970d27",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd74c0-961c-4444-a4f8-4e0410f4cdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertLayer的forward方法\n",
    "# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
    "self_attn_past_key_value = (\n",
    "    past_key_value[:2] if past_key_value is not None else None\n",
    ")\n",
    "\n",
    "self_attention_outputs = self.attention(\n",
    "    hidden_states,\n",
    "    attention_mask,\n",
    "    head_mask,\n",
    "    output_attentions=output_attentions,\n",
    "    past_key_value=self_attn_past_key_value,\n",
    ")\n",
    "\n",
    "attention_output = self_attention_outputs[0]\n",
    "outputs = self_attention_outputs[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718b0d53-0db8-49bc-8ed3-e879da06d682",
   "metadata": {},
   "source": [
    "这里是实际计算attention的地方。q是hidden_states，kv是hidden_states+past_key_value。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e55cf5dd-48c2-4458-859f-e39fb72079db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d2e8f-f19a-483a-a099-91954dd765de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertLMHeadModel的forward方法\n",
    "outputs = self.bert(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c8314-f654-4dfb-8ea5-b060644b101c",
   "metadata": {},
   "source": [
    "outputs是文本的self attention结果。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d379d1c-459c-4f00-96f9-5adf30afe5f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b641a7-b024-4137-8baf-ecd7a9a640bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertLMHeadModel的forward方法\n",
    "prediction_scores = self.cls(sequence_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca327840-88d5-42c3-b974-63f16f153211",
   "metadata": {},
   "source": [
    "将每个位置的隐状态，映射到词表大小的logits."
   ]
  },
  {
   "cell_type": "raw",
   "id": "139135dc-a9bf-4b2d-a58b-caa00c9ecb67",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0520b71-2419-41d6-9b3d-ff576ab332ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BertLMHeadModel的forward方法\n",
    "lm_loss = None\n",
    "if labels is not None:\n",
    "    # we are doing next-token prediction; shift prediction scores and input ids by one\n",
    "    shifted_prediction_scores = prediction_scores[:, :-1, :].contiguous()\n",
    "    labels = labels[:, 1:].contiguous()\n",
    "    loss_fct = CrossEntropyLoss(reduction=reduction, label_smoothing=0.1)\n",
    "    lm_loss = loss_fct(\n",
    "        shifted_prediction_scores.view(-1, self.config.vocab_size),\n",
    "        labels.view(-1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bfce4d-e9ec-4197-8ed9-51dc80e44497",
   "metadata": {},
   "source": [
    "每个位置的label是它的下一个词，将预测和label计算交叉熵，得到最终损失。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
